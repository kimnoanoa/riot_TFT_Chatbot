import json
import os
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import numpy as np

# --- ì„¤ì • (JSON íŒŒì¼ ê²½ë¡œë¥¼ 'data/' í´ë” ê¸°ì¤€ìœ¼ë¡œ ìˆ˜ì •) ---
CHAMPION_FILE = "data/champions.json"
ITEM_FILE = "data/items.json"
SYNERGY_FILE = "data/synergy_traits.json"
AUGMENT_FILE = "data/augments.json"

# --- í—¬í¼ í•¨ìˆ˜: JSON ë¡œë“œ ---
def load_json_data(filepath):
    """ì§€ì •ëœ ê²½ë¡œì—ì„œ JSON íŒŒì¼ì„ ì•ˆì „í•˜ê²Œ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"âš ï¸ ì—ëŸ¬: í•„ìˆ˜ íŒŒì¼ '{filepath}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì •ì œ ë‹¨ê³„ê°€ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None
    except json.JSONDecodeError:
        print(f"âš ï¸ ì—ëŸ¬: íŒŒì¼ '{filepath}'ì˜ JSON í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return None

# --- ë°ì´í„°í”„ë ˆì„ ì¬êµ¬ì„± (ì´ì „ ë‹¨ê³„ì˜ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì¬í˜„) ---

def reconstruct_champions_df(champions_data):
    """ì±”í”¼ì–¸ ë°ì´í„°ë¡œ ì‹œë„ˆì§€ ì›-í•« ì¸ì½”ë”© DataFrameì„ ë§Œë“­ë‹ˆë‹¤."""
    if not champions_data:
        return pd.DataFrame()
        
    df_champions = pd.DataFrame(champions_data)

    # 1. ì±”í”¼ì–¸ íŠ¹ì„± ì›-í•« ì¸ì½”ë”©
    trait_dummies = df_champions['traits'].apply(lambda x: {t: 1 for t in x}).apply(pd.Series).fillna(0)
    
    # ì±”í”¼ì–¸ ê¸°ë³¸ ì •ë³´ì™€ ì›-í•« ì¸ì½”ë”©ëœ íŠ¹ì„±ì„ ê²°í•©
    df_champs_synergy = pd.concat([
        df_champions[['id', 'name', 'cost']],
        trait_dummies
    ], axis=1)
    
    return df_champs_synergy

def reconstruct_items_df(items_data):
    """ì•„ì´í…œ ë°ì´í„°ë¡œ ìŠ¤íƒ¯ ì •ê·œí™” DataFrameì„ ë§Œë“­ë‹ˆë‹¤."""
    if not items_data:
        return pd.DataFrame()
        
    df_items = pd.DataFrame(items_data)

    # 2. ì•„ì´í…œ íš¨ê³¼ ìˆ˜ì¹˜í™” (effects ë”•ì…”ë„ˆë¦¬ ì •ê·œí™”)
    df_items_effects = pd.json_normalize(df_items['effects']).fillna(0)
    
    df_items_for_itemization = pd.concat([
        df_items[['id', 'name']], 
        df_items_effects
    ], axis=1)

    # ë¶ˆí•„ìš”í•œ API í•´ì‹œ í‚¤ ì œê±° (ì¤‘ê´„í˜¸ë¡œ ì‹œì‘í•˜ëŠ” ì—´)
    cols_to_keep = [col for col in df_items_for_itemization.columns if not (isinstance(col, str) and col.startswith('{'))]
    df_items_for_itemization = df_items_for_itemization[cols_to_keep]
    
    return df_items_for_itemization.reset_index(drop=True)


# =================================================================
# ğŸŒŸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ 1: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì´ìš©í•œ ì±”í”¼ì–¸ ì¶”ì²œ
# =================================================================
def test_champion_similarity(df, target_champion_name="ì•„íŠ¸ë¡ìŠ¤", top_n=5):
    """íŠ¹ì • ì±”í”¼ì–¸ê³¼ ì‹œë„ˆì§€ íŠ¹ì„±ì´ ê°€ì¥ ìœ ì‚¬í•œ ì±”í”¼ì–¸ì„ ì°¾ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    # ì±”í”¼ì–¸ ì´ë¦„ê³¼ id ì—´ì„ ì œì™¸í•œ íŠ¹ì„± ì—´ë§Œ ì„ íƒí•©ë‹ˆë‹¤.
    feature_cols = df.columns.drop(['id', 'name', 'cost'])
    
    if df.empty or target_champion_name not in df['name'].values or feature_cols.empty:
        if "__main__" in globals() and __name__ == "__main__": # ë©”ì¸ ì‹¤í–‰ ì‹œì—ë§Œ ì¶œë ¥
            print("\n" + "="*50)
            print(f"ğŸ¥‡ 1. ì±”í”¼ì–¸ ì‹œë„ˆì§€ ìœ ì‚¬ë„ ë¶„ì„: '{target_champion_name}' ê¸°ì¤€")
            print("="*50)
            print(f"âš ï¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ '{target_champion_name}' ì±”í”¼ì–¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    # í”¼ì²˜ ë²¡í„° ì¶”ì¶œ
    X = df[feature_cols].values
    
    # ëŒ€ìƒ ì±”í”¼ì–¸ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
    target_idx = df[df['name'] == target_champion_name].index[0]
    target_vector = X[target_idx].reshape(1, -1)
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    similarity_scores = cosine_similarity(target_vector, X)
    
    # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    similarity_df = pd.DataFrame({
        'name': df['name'],
        'score': similarity_scores[0],
        'traits': df[feature_cols].apply(lambda row: [c for c in feature_cols if row[c] == 1], axis=1)
    })
    
    # ìê¸° ìì‹ ì„ ì œì™¸í•˜ê³  ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    result = similarity_df[similarity_df['name'] != target_champion_name].sort_values(by='score', ascending=False).head(top_n)

    if "__main__" in globals() and __name__ == "__main__": # ë©”ì¸ ì‹¤í–‰ ì‹œì—ë§Œ ì¶œë ¥
        print("\n" + "="*50)
        print(f"ğŸ¥‡ 1. ì±”í”¼ì–¸ ì‹œë„ˆì§€ ìœ ì‚¬ë„ ë¶„ì„: '{target_champion_name}' ê¸°ì¤€")
        print("="*50)
        print(f"íŠ¹ì„± ë²¡í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ '{target_champion_name}'ì™€ ì‹œë„ˆì§€ê°€ ê°€ì¥ ìœ ì‚¬í•œ ì±”í”¼ì–¸:")
        print("---------------------------------------------------------------------")
        for _, row in result.iterrows():
            traits_str = ', '.join(row['traits'])
            print(f"  - {row['name']:8s} (ìœ ì‚¬ë„: {row['score']:.4f}) | ì‹œë„ˆì§€: [{traits_str}]")
            
    return result

# =================================================================
# ğŸŒŸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ 2: K-Meansë¥¼ ì´ìš©í•œ ì•„ì´í…œ êµ°ì§‘í™”
# =================================================================
def test_item_clustering(df, n_clusters=3):
    """ì•„ì´í…œ ìŠ¤íƒ¯ì„ ê¸°ë°˜ìœ¼ë¡œ K-Means êµ°ì§‘ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì—¬ ì•„ì´í…œ ìœ í˜•ì„ ë¶„ë¥˜í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    if "__main__" in globals() and __name__ == "__main__":
        print("\n" + "="*50)
        print(f"ğŸ¥ˆ 2. ì•„ì´í…œ ìŠ¤íƒ¯ ê¸°ë°˜ êµ°ì§‘í™” ({n_clusters}ê°œ ê·¸ë£¹)")
        print("="*50)

    if df.empty:
        if "__main__" in globals() and __name__ == "__main__":
            print("âš ï¸ ì•„ì´í…œ ë°ì´í„°ê°€ ë¹„ì–´ ìˆì–´ êµ°ì§‘í™” ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return pd.DataFrame()

    # --- í•µì‹¬ ìŠ¤íƒ¯ ì •ì˜ ---
    CORE_STATS = [
        'AD', 'AP', 'AS', 'CritChance', 
        'Health', 'Armor', 'MagicResist', 'Mana', 
        'ManaRestore', 'OmniVamp', 'HealOnHit', 'AttackRange'
    ]
    
    feature_cols = [col for col in CORE_STATS if col in df.columns]
    
    df_filtered = df[~df['name'].str.contains(' ìƒì§•')].copy()
    df_filtered = df_filtered[df_filtered[feature_cols].sum(axis=1) > 0].copy()
    
    X = df_filtered[feature_cols].values

    if X.shape[0] < n_clusters:
        if "__main__" in globals() and __name__ == "__main__":
            print(f"âš ï¸ ìœ íš¨ ì•„ì´í…œ ê°œìˆ˜({X.shape[0]})ê°€ êµ°ì§‘ ìˆ˜({n_clusters})ë³´ë‹¤ ì ìŠµë‹ˆë‹¤. êµ°ì§‘í™”ë¥¼ ê±´ë„ˆí‚µë‹ˆë‹¤.")
        return pd.DataFrame()

    # ìŠ¤ì¼€ì¼ë§ ë° K-Means í•™ìŠµ
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')
    df_filtered['cluster'] = kmeans.fit_predict(X_scaled)
    df_filtered['cluster_label'] = ""

    # í´ëŸ¬ìŠ¤í„° ì´ë¦„ ê²°ì • ë° ì¶œë ¥
    for i in range(n_clusters):
        cluster_items = df_filtered[df_filtered['cluster'] == i]['name'].tolist()
        centroid = scaler.inverse_transform(kmeans.cluster_centers_[i].reshape(1, -1))[0]
        centroid_stats_series = pd.Series(centroid, index=feature_cols).sort_values(ascending=False)
        top_stat = centroid_stats_series.index[0]
        top_3_stats = centroid_stats_series.head(3)
        
        damage_stats = ['AD', 'AP', 'AS', 'CritChance']
        tank_stats = ['Health', 'Armor', 'MagicResist']
        
        damage_count = sum(1 for stat in top_3_stats.index if stat in damage_stats)
        tank_count = sum(1 for stat in top_3_stats.index if stat in tank_stats)
        
        current_cluster_name = f"ê¸°íƒ€/ìœ í‹¸ë¦¬í‹° ({top_stat} ì§€í–¥)"
        
        if damage_count >= 2 and ('AP' in top_3_stats.index or 'Mana' in top_3_stats.index):
            current_cluster_name = f"AP/ë§ˆë²•ë ¥ ({top_stat} ì§€í–¥)"
        elif damage_count >= 2 and ('AD' in top_3_stats.index or 'AS' in top_3_stats.index):
            current_cluster_name = f"AD/ê³µê²©ë ¥ ({top_stat} ì§€í–¥)"
        elif tank_count >= 2:
            current_cluster_name = f"íƒ±í‚¹/ë°©ì–´ ({top_stat} ì§€í–¥)"
        
        df_filtered.loc[df_filtered['cluster'] == i, 'cluster_label'] = current_cluster_name

        if "__main__" in globals() and __name__ == "__main__":
            print(f"\n--- {current_cluster_name} ({len(cluster_items)}ê°œ ì•„ì´í…œ) ---")
            print(f"  >> ëŒ€í‘œ ìŠ¤íƒ¯(ê°€ì¥ ë†’ì€ í‰ê· ê°’): {', '.join([f'{k}: {v:.1f}' for k, v in top_3_stats.items()])}")
            print("  >> ì•„ì´í…œ ëª©ë¡:", end=" ")
            print(', '.join(cluster_items))
            
    return df_filtered

# =================================================================
# ğŸŒŸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ 3: ì±”í”¼ì–¸ ê¸°ë°˜ ì±—ë´‡ ê¸°ëŠ¥ ì‹œë®¬ë ˆì´ì…˜
# =================================================================
def simulate_tft_chatbot(df_champs, df_items_clustered, target_champion_name="ìš°ë””ë¥´"):
    """
    ì±”í”¼ì–¸ì˜ íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹œë„ˆì§€ ì¶”ì²œ ë° ì•„ì´í…œ ê·¸ë£¹ ì¶”ì²œì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤.
    """
    
    print("\n" + "="*50)
    print(f"ğŸ¥‰ 3. ì±”í”¼ì–¸ ê¸°ë°˜ ì±—ë´‡ ê¸°ëŠ¥ ì‹œë®¬ë ˆì´ì…˜: '{target_champion_name}'")
    print("="*50)
    
    if df_champs.empty or target_champion_name not in df_champs['name'].values:
        print(f"âš ï¸ ì±”í”¼ì–¸ '{target_champion_name}'ì— ëŒ€í•œ ë°ì´í„°ê°€ ë¶ˆì¶©ë¶„í•©ë‹ˆë‹¤.")
        return
        
    # 1. ì±”í”¼ì–¸ì˜ ê¸°ë³¸ ì •ë³´ì™€ íŠ¹ì„± íŒŒì•…
    champ_data = df_champs[df_champs['name'] == target_champion_name].iloc[0]
    traits = [col for col in df_champs.columns.drop(['id', 'name', 'cost']) if champ_data[col] == 1]
    
    # 2. ì‹œë„ˆì§€ ì¶”ì²œ (ê°€ì¥ ìœ ì‚¬í•œ ì±”í”¼ì–¸ ì°¾ê¸°)
    # ì±—ë´‡ ì‘ë‹µì„ ìœ„í•´ 3ê°œë§Œ ìš”ì²­í•©ë‹ˆë‹¤.
    similar_champs_df = test_champion_similarity(df_champs, target_champion_name, top_n=3)
    
    # 3. ì•„ì´í…œ ì¶”ì²œ ê·¸ë£¹ ê²°ì • (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
    
    # íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ì±”í”¼ì–¸ì˜ ì£¼ í¬ì§€ì…˜ ì¶”ë¡ 
    is_ap = any(t in traits for t in ['ë§ˆë²•ì‚¬', 'ë³„ ìˆ˜í˜¸ì', 'ì±…ëµê°€'])
    is_ad = any(t in traits for t in ['ì €ê²©ìˆ˜', 'ì´ë‹¨ì•„', 'íƒ€ê²©ëŒ€', 'í”„ë¡œë ˆìŠ¬ëŸ¬', 'ì „ìŸê¸°ê³„'])
    is_tank = any(t in traits for t in ['í—¤ë¹„ê¸‰', 'ê±°ëŒ€ ë©”í¬', 'ìš”ìƒˆ', 'íŒŒìˆ˜ê¾¼', 'ëŒê²©ëŒ€', 'ë©˜í† ']) # 'ë©˜í† ' ì¶”ê°€
    
    item_type_recommendation = []
    
    if is_tank:
        item_type_recommendation.append('íƒ±í‚¹/ë°©ì–´')
        
    if is_ap:
        item_type_recommendation.append('AP/ë§ˆë²•ë ¥')
    elif is_ad:
        item_type_recommendation.append('AD/ê³µê²©ë ¥')
    
    # íŠ¹ì„±ë§Œìœ¼ë¡œ íŒë‹¨ì´ ì–´ë ¤ìš´ ê²½ìš° í˜¹ì€ í•˜ì´ë¸Œë¦¬ë“œì¼ ê²½ìš°
    if not item_type_recommendation:
        item_type_recommendation = ['AP/ë§ˆë²•ë ¥', 'AD/ê³µê²©ë ¥', 'íƒ±í‚¹/ë°©ì–´'] # ê¸°ë³¸ê°’ (ëª¨ë‘)

    item_type_recommendation = list(set(item_type_recommendation))

    # 4. ì±—ë´‡ ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥
    
    print(f"\n==================================================")
    print(f"ğŸ—£ï¸ ì±—ë´‡ ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µ (ëŒ€ìƒ: {target_champion_name})")
    print(f"==================================================")
    
    # Q1. ì–´ë–¤ ë± ê°€ëŠ” ê²Œ ì¢‹ì„ê¹Œ? (ì£¼ë ¥ ì‹œë„ˆì§€ í™•ì¸)
    print(f"Q: '{target_champion_name}' ë–´ëŠ”ë° ì–´ë–¤ ë± ê°€ëŠ” ê²Œ ì¢‹ì„ê¹Œ?")
    print(f"A: {target_champion_name} ì±”í”¼ì–¸ì˜ ì£¼ë ¥ íŠ¹ì„±ì€ **{', '.join(traits)}**ì…ë‹ˆë‹¤.")
    if len(traits) >= 2:
        print(f"ì´ íŠ¹ì„±ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ **{traits[0]}** ë˜ëŠ” **{traits[1]}** ë±ì˜ ì´ˆë°˜ ë¹Œë“œì—…ì„ ì¶”ì²œí•©ë‹ˆë‹¤.")
    else:
        print(f"ì´ íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ **{traits[0]}** ë±ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¹Œë“œì—…ì„ ì‹œì‘í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤.")
    
    print("-" * 30)
    
    # Q2. í…œ ë­ ë„£ëŠ” ê²Œ ì¢‹ì•„? (ì•„ì´í…œ ê·¸ë£¹ ì¶”ì²œ)
    print(f"Q: '{target_champion_name}'í•œí…Œ í…œ ë­ ë„£ëŠ” ê²Œ ì¢‹ì•„?")
    print(f"A: {target_champion_name}ì˜ íŠ¹ì„±({', '.join(traits)}) ë¶„ì„ ê²°ê³¼, ì£¼ë¡œ **{' ë° '.join(item_type_recommendation)}** ìœ í˜•ì˜ ì•„ì´í…œì´ ì˜ ë§ìŠµë‹ˆë‹¤.")
    
    recommended_items = []
    for type_name in item_type_recommendation:
        if df_items_clustered.empty: continue
        
        # í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸”ì„ í¬í•¨í•˜ëŠ” ì •í™•í•œ ì´ë¦„ ì°¾ê¸°
        cluster_name_match = [label for label in df_items_clustered['cluster_label'].unique() if type_name in label]
        
        if cluster_name_match:
            # í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì„ì˜ë¡œ 3ê°œ ì•„ì´í…œì„ ì¶”ì¶œ (ì˜ˆì‹œ)
            # ì´ë¦„ì´ 'ë„ì ì˜ ì¥ê°‘' ì²˜ëŸ¼ ì¤‘ë³µë˜ëŠ” ì•„ì´í…œì´ ìˆìœ¼ë¯€ë¡œ setìœ¼ë¡œ ì¤‘ë³µ ì œê±° í›„ ì¶”ì¶œ
            items = df_items_clustered[df_items_clustered['cluster_label'] == cluster_name_match[0]]['name']
            recommended_items.extend(list(set(items.tolist()))[:3])
    
    if recommended_items:
        print(f"   - ì¶”ì²œ ì•„ì´í…œ(ì˜ˆì‹œ): **{', '.join(list(set(recommended_items)))}** ë“±")
    else:
        print(f"   - í˜„ì¬ ì•„ì´í…œ ë°ì´í„° ë¶„ì„ìœ¼ë¡œëŠ” ëª…í™•í•œ ì¶”ì²œ ì•„ì´í…œì„ ì°¾ê¸° ì–´ë µìŠµë‹ˆë‹¤. ì•„ì´í…œ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ ë¨¼ì € í™•ì¸í•´ì£¼ì„¸ìš”.")

    print("-" * 30)
    
    # Q3. ê°™ì´ ê°ˆ ì‹œë„ˆì§€ ë±ìœ¼ë¡œ ë­˜ ì¶”ì²œí•´? (ìœ ì‚¬ ì±”í”¼ì–¸ ì¶”ì²œ)
    print(f"Q: '{target_champion_name}'ë‘ ê°™ì´ ê°ˆ ì‹œë„ˆì§€ ë±ìœ¼ë¡œ ë­˜ ì¶”ì²œí•´?")
    
    if not similar_champs_df.empty:
        print(f"A: {target_champion_name}ì™€ íŠ¹ì„± êµ¬ì„±ì´ ìœ ì‚¬í•˜ì—¬ í•¨ê»˜ ì‚¬ìš©í•˜ê¸° ì¢‹ì€ ì±”í”¼ì–¸ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ (ìœ ì‚¬ë„ ìˆœ):")
        for _, row in similar_champs_df.iterrows():
            traits_str = ', '.join(row['traits'])
            print(f"   - **{row['name']}**: ì‹œë„ˆì§€ [{traits_str}]")
    else:
        print(f"A: ì‹œë„ˆì§€ ìœ ì‚¬ë„ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        
    print(f"==================================================\n")

# =================================================================
# ğŸŒŸ ë©”ì¸ ì‹¤í–‰ ë¸”ë¡
# =================================================================
if __name__ == "__main__":
    
    print("ğŸš€ TFT ë°ì´í„° ë¶„ì„ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

    # 1. ë°ì´í„° ë¡œë“œ
    champions_data = load_json_data(CHAMPION_FILE)
    items_data = load_json_data(ITEM_FILE)

    if not champions_data or not items_data:
        print("í•„ìˆ˜ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨. í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    else:
        # 2. DataFrame ì¬êµ¬ì„±
        df_champs_synergy = reconstruct_champions_df(champions_data)
        df_items_for_itemization = reconstruct_items_df(items_data)

        # 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ê¸°ì¡´ í…ŒìŠ¤íŠ¸)
        # ì±”í”¼ì–¸ ìœ ì‚¬ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ì±—ë´‡ ì‹œë®¬ë ˆì´ì…˜ì— ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë³€ìˆ˜ë¡œ ë°›ìŠµë‹ˆë‹¤.
        df_similar_champs = test_champion_similarity(df_champs_synergy, target_champion_name="ì•„íŠ¸ë¡ìŠ¤")
        # ì•„ì´í…œ êµ°ì§‘í™” ê²°ê³¼ë¥¼ ì±—ë´‡ ì‹œë®¬ë ˆì´ì…˜ì— ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë³€ìˆ˜ë¡œ ë°›ìŠµë‹ˆë‹¤.
        df_items_clustered = test_item_clustering(df_items_for_itemization, n_clusters=3)
        
        # 4. ì±—ë´‡ ê¸°ëŠ¥ ì‹œë®¬ë ˆì´ì…˜ (ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸)
        # ì±”í”¼ì–¸ 'ìš°ë””ë¥´'ì— ëŒ€í•œ ì±—ë´‡ ê¸°ëŠ¥ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        simulate_tft_chatbot(df_champs_synergy, df_items_clustered, target_champion_name="íŠ¸ìœ„ìŠ¤í‹°ë“œ í˜ì´íŠ¸")

    print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ.")